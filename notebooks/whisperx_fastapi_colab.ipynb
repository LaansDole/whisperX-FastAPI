{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaansDole/whisperX-FastAPI/blob/main/notebooks/whisperx_fastapi_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgRmhCYcFPv9"
      },
      "source": [
        "# WhisperX FastAPI on Google Colab\n",
        "\n",
        "This notebook sets up and runs the WhisperX FastAPI project on Google Colab, utilizing its GPU for speech-to-text processing. The API service is exposed through a Cloudflare tunnel to allow external access.\n",
        "\n",
        "## Features\n",
        "\n",
        "- Speech-to-text transcription\n",
        "- Audio alignment\n",
        "- Speaker diarization\n",
        "- Combined services\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Google Colab with GPU runtime\n",
        "- Hugging Face token for model access\n",
        "- Cloudflare account (free tier works fine)\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1. Make sure you're running this notebook with GPU runtime\n",
        "2. Execute each cell in order\n",
        "3. Use the Cloudflare tunnel URL to access the API\n",
        "\n",
        "Let's start by checking if we have GPU access and setting up the environment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "UowbTabZFS0k",
        "outputId": "168a9669-14c1-4f96-b9b0-a3198ec23954"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0KVaZ_zFPwC"
      },
      "source": [
        "## 1. Install System Dependencies\n",
        "\n",
        "First, we need to install the required system packages and utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9foV_tYFPwC",
        "outputId": "cfcc3997-9f4e-4709-bb40-d5ddaf72a05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,798 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,747 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,340 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,051 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,561 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,703 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,024 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,532 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,253 kB]\n",
            "Fetched 32.5 MB in 3s (9,947 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install ffmpeg for audio/video processing\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# Install git and other utilities\n",
        "!apt-get install -y git curl wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfCgeb4JFPwC"
      },
      "source": [
        "## 2. Clone the WhisperX FastAPI Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlMBW9VAFPwC",
        "outputId": "3fb651e4-d1a8-4a24-84d1-2b16b854dafd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'whisperX-FastAPI' already exists and is not an empty directory.\n",
            "total 96\n",
            "drwxr-xr-x 9 root root 4096 Jun 20 11:35 .\n",
            "drwxr-xr-x 1 root root 4096 Jun 20 11:35 ..\n",
            "drwxr-xr-x 4 root root 4096 Jun 20 11:35 app\n",
            "drwxr-xr-x 2 root root 4096 Jun 20 11:35 .devcontainer\n",
            "-rw-r--r-- 1 root root  531 Jun 20 11:35 docker-compose.yml\n",
            "-rw-r--r-- 1 root root 1627 Jun 20 11:35 dockerfile\n",
            "-rw-r--r-- 1 root root  331 Jun 20 11:35 .dockerignore\n",
            "drwxr-xr-x 8 root root 4096 Jun 20 11:35 .git\n",
            "drwxr-xr-x 3 root root 4096 Jun 20 11:35 .github\n",
            "-rw-r--r-- 1 root root   52 Jun 20 11:35 .gitignore\n",
            "-rw-r--r-- 1 root root  207 Jun 20 11:35 .gitleaks.toml\n",
            "-rw-r--r-- 1 root root 1070 Jun 20 11:35 LICENSE\n",
            "-rw-r--r-- 1 root root   39 Jun 20 11:35 .markdownlint.json\n",
            "-rw-r--r-- 1 root root 1963 Jun 20 11:35 .pre-commit-config.yaml\n",
            "-rw-r--r-- 1 root root  532 Jun 20 11:35 pyproject.toml\n",
            "-rw-r--r-- 1 root root 9405 Jun 20 11:35 README.md\n",
            "drwxr-xr-x 2 root root 4096 Jun 20 11:35 requirements\n",
            "-rw-r--r-- 1 root root  153 Jun 20 11:35 requirements.txt\n",
            "-rw-r--r-- 1 root root   86 Jun 20 11:35 setup.cfg\n",
            "-rwxr-xr-x 1 root root   77 Jun 20 11:35 start.sh\n",
            "drwxr-xr-x 3 root root 4096 Jun 20 11:35 tests\n",
            "drwxr-xr-x 2 root root 4096 Jun 20 11:35 .vscode\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/pavelzbornik/whisperX-FastAPI.git\n",
        "!cd whisperX-FastAPI && ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueqDc01EFPwD"
      },
      "source": [
        "## 3. Create Python Virtual Environment and Install Dependencies\n",
        "\n",
        "We'll install PyTorch with CUDA support and all required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJrF6J1tFPwD",
        "outputId": "565bb87b-94a7-410f-96bf-327341e09e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting colorlog==6.9.0 (from -r requirements/prod.txt (line 1))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: fastapi==0.115.12 in /usr/local/lib/python3.11/dist-packages (from -r requirements/prod.txt (line 2)) (0.115.12)\n",
            "Collecting gunicorn==23.0.0 (from -r requirements/prod.txt (line 3))\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements/prod.txt (line 4)) (0.28.1)\n",
            "Collecting numba==0.61.0 (from -r requirements/prod.txt (line 5))\n",
            "  Downloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting python-dotenv==1.1.0 (from -r requirements/prod.txt (line 6))\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: python-multipart==0.0.20 in /usr/local/lib/python3.11/dist-packages (from -r requirements/prod.txt (line 7)) (0.0.20)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements/prod.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: uvicorn==0.34.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements/prod.txt (line 9)) (0.34.3)\n",
            "Collecting whisperx==3.3.4 (from -r requirements/prod.txt (line 10))\n",
            "  Downloading whisperx-3.3.4-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting codespell==2.4.1 (from -r requirements/dev.txt (line 5))\n",
            "  Downloading codespell-2.4.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pre-commit==4.2.0 (from -r requirements/dev.txt (line 8))\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pytest==8.4.0 (from -r requirements/dev.txt (line 11))\n",
            "  Downloading pytest-8.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting pytest-cov==6.1.1 (from -r requirements/dev.txt (line 12))\n",
            "  Downloading pytest_cov-6.1.1-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: ruff==0.11.13 in /usr/local/lib/python3.11/dist-packages (from -r requirements/dev.txt (line 16)) (0.11.13)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.12->-r requirements/prod.txt (line 2)) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.12->-r requirements/prod.txt (line 2)) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.12->-r requirements/prod.txt (line 2)) (4.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn==23.0.0->-r requirements/prod.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->-r requirements/prod.txt (line 4)) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->-r requirements/prod.txt (line 4)) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->-r requirements/prod.txt (line 4)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.28.1->-r requirements/prod.txt (line 4)) (3.10)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.0->-r requirements/prod.txt (line 5))\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<2.2,>=1.24 in /usr/local/lib/python3.11/dist-packages (from numba==0.61.0->-r requirements/prod.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.34.3->-r requirements/prod.txt (line 9)) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.34.3->-r requirements/prod.txt (line 9)) (0.16.0)\n",
            "Collecting ctranslate2<4.5.0 (from whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading ctranslate2-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting faster-whisper>=1.1.1 (from whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.9.1)\n",
            "Collecting onnxruntime>=1.19 (from whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting pandas>=2.2.3 (from whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyannote-audio>=3.3.2 (from whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading pyannote.audio-3.3.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.48.0 in /usr/local/lib/python3.11/dist-packages (from whisperx==3.3.4->-r requirements/prod.txt (line 10)) (4.52.4)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit==4.2.0->-r requirements/dev.txt (line 8))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit==4.2.0->-r requirements/dev.txt (line 8))\n",
            "  Downloading identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit==4.2.0->-r requirements/dev.txt (line 8))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit==4.2.0->-r requirements/dev.txt (line 8)) (6.0.2)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit==4.2.0->-r requirements/dev.txt (line 8))\n",
            "  Downloading virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.11/dist-packages (from pytest==8.4.0->-r requirements/dev.txt (line 11)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest==8.4.0->-r requirements/dev.txt (line 11)) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from pytest==8.4.0->-r requirements/dev.txt (line 11)) (2.19.1)\n",
            "Collecting coverage>=7.5 (from coverage[toml]>=7.5->pytest-cov==6.1.1->-r requirements/dev.txt (line 12))\n",
            "  Downloading coverage-7.9.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<4.5.0->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (75.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.33.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper>=1.1.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.21.1)\n",
            "Collecting av>=11 (from faster-whisper>=1.1.1->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2024.11.6)\n",
            "Collecting coloredlogs (from onnxruntime>=1.19->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.19->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2025.2)\n",
            "Collecting asteroid-filterbanks>=0.4 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.8.1)\n",
            "Collecting lightning>=2.0.1 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.3.0)\n",
            "Collecting pyannote.core>=5.0.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.database>=5.0.1 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyannote.metrics>=3.2 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyannote.pipeline>=3.0.1 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
            "Collecting pytorch-metric-learning>=2.1.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (13.9.4)\n",
            "Collecting semver>=3.0.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.13.1)\n",
            "Collecting speechbrain>=1.0.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tensorboardX>=2.6 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting torch-audiomentations>=0.11.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting torchmetrics>=0.11.0 (from pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.115.12->-r requirements/prod.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.115.12->-r requirements/prod.txt (line 2)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.115.12->-r requirements/prod.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx==0.28.1->-r requirements/prod.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.19->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.0->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.0->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.5.3)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit==4.2.0->-r requirements/dev.txt (line 8))\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit==4.2.0->-r requirements/dev.txt (line 8)) (4.3.8)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper>=1.1.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.1.3)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<3.0,>=2.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.15.3)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.6.1)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.10.0)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.17.1)\n",
            "Collecting hyperpyyaml (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.2.0)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.19->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.48.0->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.11.15)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.2.3)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.0.41)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.6.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.5.4)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.20.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (1.1.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10))\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx==3.3.4->-r requirements/prod.txt (line 10)) (3.2.3)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading whisperx-3.3.4-py3-none-any.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading codespell-2.4.1-py3-none-any.whl (344 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.5/344.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-8.4.0-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.8/363.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_cov-6.1.1-py3-none-any.whl (23 kB)\n",
            "Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading coverage-7.9.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.6/244.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/37.4 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading identify-2.6.12-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.audio-3.3.2-py2.py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.31.2-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt, julius\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=1aa321a14fb0286dfa8488e0cd28523bd322cc28d37c50971842b6763237b235\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=97372993e89cab42f92230f59d873fb380d785a4010bff991be52372e52f8642\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "Successfully built docopt julius\n",
            "Installing collected packages: primePy, docopt, distlib, virtualenv, tensorboardX, semver, ruamel.yaml.clib, python-dotenv, pytest, nodeenv, llvmlite, lightning-utilities, identify, humanfriendly, gunicorn, ctranslate2, coverage, colorlog, codespell, cfgv, av, ruamel.yaml, pyannote.core, pre-commit, pandas, numba, coloredlogs, alembic, pytest-cov, optuna, onnxruntime, hyperpyyaml, torchmetrics, pytorch-metric-learning, pyannote.database, julius, faster-whisper, asteroid-filterbanks, torch-pitch-shift, speechbrain, pytorch-lightning, pyannote.pipeline, pyannote.metrics, torch-audiomentations, lightning, pyannote-audio, whisperx\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.3.5\n",
            "    Uninstalling pytest-8.3.5:\n",
            "      Successfully uninstalled pytest-8.3.5\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.61.0 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.16.2 asteroid-filterbanks-0.4.0 av-14.4.0 cfgv-3.4.0 codespell-2.4.1 coloredlogs-15.0.1 colorlog-6.9.0 coverage-7.9.1 ctranslate2-4.4.0 distlib-0.3.9 docopt-0.6.2 faster-whisper-1.1.1 gunicorn-23.0.0 humanfriendly-10.0 hyperpyyaml-1.2.2 identify-2.6.12 julius-0.2.7 lightning-2.5.1.post0 lightning-utilities-0.14.3 llvmlite-0.44.0 nodeenv-1.9.1 numba-0.61.0 onnxruntime-1.22.0 optuna-4.4.0 pandas-2.3.0 pre-commit-4.2.0 primePy-1.3 pyannote-audio-3.3.2 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pyannote.pipeline-3.0.1 pytest-8.4.0 pytest-cov-6.1.1 python-dotenv-1.1.0 pytorch-lightning-2.5.1.post0 pytorch-metric-learning-2.8.1 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 semver-3.0.4 speechbrain-1.0.3 tensorboardX-2.6.4 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchmetrics-1.7.3 virtualenv-20.31.2 whisperx-3.3.4\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (6.9.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.11\n"
          ]
        }
      ],
      "source": [
        "# Install PyTorch with CUDA support\n",
        "!cd whisperX-FastAPI && pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install project requirements\n",
        "!cd whisperX-FastAPI && pip install -r requirements/dev.txt\n",
        "\n",
        "# Install additional packages for Colab environment\n",
        "!cd whisperX-FastAPI && pip install colorlog pyngrok python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJQd3yTqFPwD"
      },
      "source": [
        "## 4. Set Up Environment Variables\n",
        "\n",
        "Configure the required environment variables for WhisperX. You'll need to enter your Hugging Face API token to access the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyTAXbREFPwD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Enter your Hugging Face token here\n",
        "HF_TOKEN = input(\"Enter your Hugging Face token: \")\n",
        "\n",
        "# Choose Whisper model size\n",
        "WHISPER_MODEL = input(\"Enter Whisper model size (default: tiny): \") or \"tiny\"\n",
        "\n",
        "# Set log level\n",
        "LOG_LEVEL = \"INFO\"\n",
        "\n",
        "# Create .env file\n",
        "env_content = f\"\"\"HF_TOKEN={HF_TOKEN}\n",
        "WHISPER_MODEL={WHISPER_MODEL}\n",
        "LOG_LEVEL={LOG_LEVEL}\n",
        "DEVICE=cuda\n",
        "COMPUTE_TYPE=float16\n",
        "DB_URL=sqlite:///records.db\n",
        "\"\"\"\n",
        "\n",
        "with open(\"whisperX-FastAPI/.env\", \"w\") as f:\n",
        "    f.write(env_content)\n",
        "\n",
        "print(\"Environment configuration completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY6saexJFPwD"
      },
      "source": [
        "## 5. Install and Configure Cloudflare Tunnel\n",
        "\n",
        "We'll use Cloudflare tunnels to expose the FastAPI service to the internet, allowing you to access it from your browser or other clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U9NZCfdFPwD",
        "outputId": "fc93c958-e1c8-48bc-ef67-c48628651804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-20 12:03:08--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-amd64 [following]\n",
            "--2025-06-20 12:03:08--  https://github.com/cloudflare/cloudflared/releases/download/2025.6.1/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/015db4d3-519c-4e00-a1a6-289640709684?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250620%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250620T120308Z&X-Amz-Expires=300&X-Amz-Signature=950ba60ca0e71f701ab9120d68587511484448d19f58cba179ce783ad9b73faf&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-06-20 12:03:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/015db4d3-519c-4e00-a1a6-289640709684?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250620%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250620T120308Z&X-Amz-Expires=300&X-Amz-Signature=950ba60ca0e71f701ab9120d68587511484448d19f58cba179ce783ad9b73faf&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41164185 (39M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared’\n",
            "\n",
            "cloudflared         100%[===================>]  39.26M   182MB/s    in 0.2s    \n",
            "\n",
            "2025-06-20 12:03:08 (182 MB/s) - ‘cloudflared’ saved [41164185/41164185]\n",
            "\n",
            "Cloudflare tunnel client installed.\n"
          ]
        }
      ],
      "source": [
        "# Download and install cloudflared\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared\n",
        "\n",
        "print(\"Cloudflare tunnel client installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji-K4diXFPwE"
      },
      "source": [
        "## 6. Start the FastAPI Service\n",
        "\n",
        "Now we'll run the FastAPI application in the background and expose it through the Cloudflare tunnel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25200ab8",
        "outputId": "235eacd9-c910-4c15-cf59-0263f9bf34a4"
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# Function to start FastAPI server in a background process\n",
        "def start_fastapi_background():\n",
        "    print(\"Attempting to start FastAPI server in background using subprocess...\")\n",
        "    try:\n",
        "        # Define the command to run\n",
        "        # Use 'exec' to replace the current shell process with uvicorn,\n",
        "        # and run in the background with '&'\n",
        "        # Ensure the virtual environment is sourced\n",
        "        command = \"uvicorn app.main:app --host 0.0.0.0 --port 8001 --log-config app/uvicorn_log_conf.yaml --log-level info &\"\n",
        "\n",
        "        # Start the subprocess\n",
        "        # We don't need to capture stdout/stderr if we want it to run truly in background\n",
        "        # If we need to debug, we might temporarily remove '&' and check output\n",
        "        process = subprocess.Popen(command, shell=True, preexec_fn=os.setsid)\n",
        "\n",
        "        print(f\"FastAPI background process started with PID: {process.pid}\")\n",
        "        return process\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error starting FastAPI background process: {e}\")\n",
        "        return None\n",
        "\n",
        "# Start the background process\n",
        "fastapi_process = start_fastapi_background()\n",
        "\n",
        "# Give the server a moment to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Now check if the server is reachable\n",
        "server_url = \"http://0.0.0.0:8001\"\n",
        "print(f\"Attempting to connect to FastAPI server at {server_url}...\")\n",
        "\n",
        "try:\n",
        "    response = requests.get(server_url, timeout=5)\n",
        "    print(f\"Successfully connected to {server_url}. Status code: {response.status_code}\")\n",
        "    if response.status_code in [200, 404, 422]:\n",
        "        print(\"FastAPI server appears to be running.\")\n",
        "    else:\n",
        "        print(\"Received unexpected status code. Server might be running but not as expected.\")\n",
        "\n",
        "except requests.exceptions.ConnectionError:\n",
        "    print(f\"Error: Could not connect to {server_url}. The server might not be running or is not accessible.\")\n",
        "except requests.exceptions.Timeout:\n",
        "    print(f\"Error: Request to {server_url} timed out.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Store the process globally if needed for later shutdown\n",
        "globals()['fastapi_background_process'] = fastapi_process"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to start FastAPI server in background using subprocess...\n",
            "FastAPI background process started with PID: 10368\n",
            "Attempting to connect to FastAPI server at http://0.0.0.0:8001...\n",
            "Successfully connected to http://0.0.0.0:8001. Status code: 200\n",
            "FastAPI server appears to be running.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Run cloudflared tunnel in background and get the public URL\n",
        "cloudflared_proc = subprocess.Popen(\n",
        "    ['./cloudflared', 'tunnel', '--url', 'http://0.0.0.0:8001', '--no-autoupdate'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "tunnel_url = None\n",
        "for line in cloudflared_proc.stdout:\n",
        "    print(line.strip())\n",
        "    match = re.search(r'(https://.*\\.trycloudflare\\.com)', line)\n",
        "    if match:\n",
        "        tunnel_url = match.group(1)\n",
        "        break\n",
        "\n",
        "if tunnel_url:\n",
        "    print(f\"\\n✅ Public URL for Ollama:\\n{tunnel_url}\")\n",
        "else:\n",
        "    raise RuntimeError(\"❌ Could not find public Cloudflare URL.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrzQIdfoJJa1",
        "outputId": "1e71bc97-c32c-47af-b5e0-af659635d986"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-20T12:04:17Z INF Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "2025-06-20T12:04:17Z INF Requesting new quick Tunnel on trycloudflare.com...\n",
            "2025-06-20T12:04:21Z INF +--------------------------------------------------------------------------------------------+\n",
            "2025-06-20T12:04:21Z INF |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "2025-06-20T12:04:21Z INF |  https://available-picture-mem-transform.trycloudflare.com                                 |\n",
            "\n",
            "✅ Public URL for Ollama:\n",
            "https://available-picture-mem-transform.trycloudflare.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey4uGZGRFPwE"
      },
      "source": [
        "## 7. Monitor GPU Usage\n",
        "\n",
        "You can monitor GPU usage while the service is running to ensure it's properly utilizing the available resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbGOrKEOFPwE"
      },
      "outputs": [],
      "source": [
        "# Check GPU usage\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ4SCTivFPwE"
      },
      "source": [
        "## 8. Test the API\n",
        "\n",
        "Here's an example of how to use the API to transcribe an audio file uploaded to Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsmhvZtCFPwF"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from google.colab import files\n",
        "import os\n",
        "# Function to upload a file to the WhisperX API\n",
        "def transcribe_audio(file_path, api_url):\n",
        "    # API endpoint for speech-to-text\n",
        "    endpoint = f\"{api_url}/speech-to-text\"\n",
        "\n",
        "    # Parameters for the request\n",
        "    params = {\n",
        "        \"model\": WHISPER_MODEL,  # Use the same model as configured earlier\n",
        "        \"language\": \"en\"  # Change this to match your audio language\n",
        "    }\n",
        "\n",
        "    # Create the multipart form data\n",
        "    with open(file_path, \"rb\") as audio_file:\n",
        "        files = {\"audio_file\": (os.path.basename(file_path), audio_file)}\n",
        "        response = requests.post(endpoint, params=params, files=files)\n",
        "\n",
        "    # Return the response\n",
        "    return response.json()\n",
        "\n",
        "# Upload an audio file\n",
        "print(\"Please upload an audio file (supported formats: mp3, wav, m4a, etc.)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process the uploaded file\n",
        "if uploaded:\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "\n",
        "    # Check if tunnel URL is available\n",
        "    if tunnel_url:\n",
        "        print(f\"Transcribing {file_name}...\")\n",
        "        result = transcribe_audio(file_name, tunnel_url)\n",
        "\n",
        "        # Display the identifier for checking the task status\n",
        "        if \"identifier\" in result:\n",
        "            print(f\"\\nTask identifier: {result['identifier']}\")\n",
        "            print(f\"\\nCheck the task status at: {tunnel_url}/task/{result['identifier']}\")\n",
        "            display.display(display.HTML(f'<a href=\"{tunnel_url}/task/{result[\"identifier\"]}\" target=\"_blank\">Check Task Status</a>'))\n",
        "        else:\n",
        "            print(\"Error:\", result)\n",
        "    else:\n",
        "        print(\"Tunnel URL is not available. Make sure the FastAPI service and Cloudflare tunnel are running.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2opVH6LgFPwF"
      },
      "source": [
        "## 9. Check Task Status\n",
        "\n",
        "Use this cell to check the status of your transcription task using the task identifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6OcBz3OFPwF"
      },
      "outputs": [],
      "source": [
        "# Function to check task status\n",
        "def check_task_status(task_id, api_url):\n",
        "    endpoint = f\"{api_url}/task/{task_id}\"\n",
        "    response = requests.get(endpoint)\n",
        "    return response.json()\n",
        "\n",
        "# Enter task identifier\n",
        "task_id = input(\"Enter task identifier: \")\n",
        "\n",
        "# Check task status\n",
        "if tunnel_url and task_id:\n",
        "    status = check_task_status(task_id, tunnel_url)\n",
        "    print(\"Task Status:\")\n",
        "    import json\n",
        "    print(json.dumps(status, indent=2))\n",
        "else:\n",
        "    print(\"Tunnel URL or task ID is not available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VceFvDDVFPwF"
      },
      "source": [
        "## 10. Shutdown Services\n",
        "\n",
        "When you're done, use this cell to properly shut down the services and free up resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYbwZ_ktFPwF"
      },
      "outputs": [],
      "source": [
        "# Function to shut down services\n",
        "def shutdown_services():\n",
        "    global fastapi_process, tunnel_process\n",
        "\n",
        "    print(\"Shutting down services...\")\n",
        "\n",
        "    # Terminate Cloudflare tunnel\n",
        "    if tunnel_process:\n",
        "        tunnel_process.terminate()\n",
        "        tunnel_process.wait()\n",
        "        print(\"Cloudflare tunnel stopped.\")\n",
        "\n",
        "    # Terminate FastAPI server\n",
        "    if fastapi_process:\n",
        "        fastapi_process.terminate()\n",
        "        fastapi_process.wait()\n",
        "        print(\"FastAPI server stopped.\")\n",
        "\n",
        "    print(\"All services have been shut down.\")\n",
        "\n",
        "# Shut down the services\n",
        "shutdown_services()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KkSIjl4FPwG"
      },
      "source": [
        "## 11. Cleanup\n",
        "\n",
        "Finally, clean up any temporary files and free up GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0e9m8RoFPwG"
      },
      "outputs": [],
      "source": [
        "# Clean up temporary files\n",
        "!rm -f cloudflared-linux-amd64.deb\n",
        "\n",
        "# Free up GPU memory (if any is still in use)\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"GPU memory cleared.\")\n",
        "\n",
        "print(\"Cleanup completed. You can now close this notebook or run it again if needed.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}