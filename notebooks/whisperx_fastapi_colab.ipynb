{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaansDole/whisperX-FastAPI/blob/main/notebooks/whisperx_fastapi_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgRmhCYcFPv9"
      },
      "source": [
        "# WhisperX FastAPI on Google Colab\n",
        "\n",
        "This notebook sets up and runs the WhisperX FastAPI project on Google Colab, utilizing its GPU for speech-to-text processing. The API service is exposed through a Cloudflare tunnel to allow external access.\n",
        "\n",
        "## Features\n",
        "\n",
        "- Speech-to-text transcription\n",
        "- Audio alignment\n",
        "- Speaker diarization\n",
        "- Combined services\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Google Colab with GPU runtime\n",
        "- Hugging Face token for model access\n",
        "- Cloudflare account (free tier works fine)\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1. Make sure you're running this notebook with GPU runtime\n",
        "2. Execute each cell in order\n",
        "3. Use the Cloudflare tunnel URL to access the API\n",
        "\n",
        "Let's start by checking if we have GPU access and setting up the environment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "UowbTabZFS0k",
        "outputId": "168a9669-14c1-4f96-b9b0-a3198ec23954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0KVaZ_zFPwC"
      },
      "source": [
        "## 1. Install System Dependencies\n",
        "\n",
        "First, we need to install the required system packages and utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9foV_tYFPwC",
        "outputId": "5112527c-e62d-4bae-b87d-5959699da243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install ffmpeg for audio/video processing\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "\n",
        "# Install git and other utilities\n",
        "!apt-get install -y git curl wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfCgeb4JFPwC"
      },
      "source": [
        "## 2. Clone the WhisperX FastAPI Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlMBW9VAFPwC",
        "outputId": "c6737b72-bbaa-41ac-f58e-84c328b18b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'whisperX-FastAPI' already exists and is not an empty directory.\n",
            "total 40312\n",
            "drwxr-xr-x 10 root root     4096 Jun 23 15:33 .\n",
            "drwxr-xr-x  1 root root     4096 Jun 23 15:28 ..\n",
            "drwxr-xr-x  5 root root     4096 Jun 23 15:29 app\n",
            "-rwxr-xr-x  1 root root 41164185 Jun 17 12:46 cloudflared\n",
            "drwxr-xr-x  2 root root     4096 Jun 23 15:25 .devcontainer\n",
            "-rw-r--r--  1 root root      531 Jun 23 15:25 docker-compose.yml\n",
            "-rw-r--r--  1 root root     1627 Jun 23 15:25 dockerfile\n",
            "-rw-r--r--  1 root root      331 Jun 23 15:25 .dockerignore\n",
            "-rw-r--r--  1 root root      143 Jun 23 15:28 .env\n",
            "drwxr-xr-x  8 root root     4096 Jun 23 15:25 .git\n",
            "drwxr-xr-x  3 root root     4096 Jun 23 15:25 .github\n",
            "-rw-r--r--  1 root root       52 Jun 23 15:25 .gitignore\n",
            "-rw-r--r--  1 root root      207 Jun 23 15:25 .gitleaks.toml\n",
            "-rw-r--r--  1 root root     1070 Jun 23 15:25 LICENSE\n",
            "-rw-r--r--  1 root root       39 Jun 23 15:25 .markdownlint.json\n",
            "-rw-r--r--  1 root root     1963 Jun 23 15:25 .pre-commit-config.yaml\n",
            "-rw-r--r--  1 root root      532 Jun 23 15:25 pyproject.toml\n",
            "-rw-r--r--  1 root root     9405 Jun 23 15:25 README.md\n",
            "-rw-r--r--  1 root root     8192 Jun 23 15:29 records.db\n",
            "drwxr-xr-x  2 root root     4096 Jun 23 15:25 requirements\n",
            "-rw-r--r--  1 root root      153 Jun 23 15:25 requirements.txt\n",
            "-rw-r--r--  1 root root       86 Jun 23 15:25 setup.cfg\n",
            "-rwxr-xr-x  1 root root       77 Jun 23 15:25 start.sh\n",
            "drwxr-xr-x  3 root root     4096 Jun 23 15:25 tests\n",
            "drwxr-xr-x  2 root root     4096 Jun 23 15:25 .vscode\n",
            "drwxr-xr-x  9 root root     4096 Jun 23 15:33 whisperX-FastAPI\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/pavelzbornik/whisperX-FastAPI.git\n",
        "!cd whisperX-FastAPI && ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueqDc01EFPwD"
      },
      "source": [
        "## 3. Create Python Virtual Environment and Install Dependencies\n",
        "\n",
        "We'll install PyTorch with CUDA support and all required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJrF6J1tFPwD"
      },
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA support\n",
        "!cd whisperX-FastAPI && pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install project requirements\n",
        "!cd whisperX-FastAPI && pip install -r requirements/dev.txt\n",
        "\n",
        "# Install additional packages for Colab environment\n",
        "!cd whisperX-FastAPI && pip install colorlog pyngrok python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJQd3yTqFPwD"
      },
      "source": [
        "## 4. Set Up Environment Variables\n",
        "\n",
        "Configure the required environment variables for WhisperX. You'll need to enter your Hugging Face API token to access the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyTAXbREFPwD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Enter your Hugging Face token here\n",
        "HF_TOKEN = input(\"Enter your Hugging Face token: \")\n",
        "\n",
        "# Choose Whisper model size\n",
        "WHISPER_MODEL = input(\"Enter Whisper model size (default: tiny): \") or \"tiny\"\n",
        "\n",
        "# Set log level\n",
        "LOG_LEVEL = \"INFO\"\n",
        "\n",
        "# Create .env file\n",
        "env_content = f\"\"\"HF_TOKEN={HF_TOKEN}\n",
        "WHISPER_MODEL={WHISPER_MODEL}\n",
        "LOG_LEVEL={LOG_LEVEL}\n",
        "DEVICE=cuda\n",
        "COMPUTE_TYPE=float16\n",
        "DB_URL=sqlite:///records.db\n",
        "\"\"\"\n",
        "\n",
        "with open(\"whisperX-FastAPI/.env\", \"w\") as f:\n",
        "    f.write(env_content)\n",
        "\n",
        "print(\"Environment configuration completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY6saexJFPwD"
      },
      "source": [
        "## 5. Install and Configure Cloudflare Tunnel\n",
        "\n",
        "We'll use Cloudflare tunnels to expose the FastAPI service to the internet, allowing you to access it from your browser or other clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U9NZCfdFPwD",
        "outputId": "9d2f4701-3084-41ab-93bb-2feb59c90bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloudflared: Text file busy\n",
            "Cloudflare tunnel client installed.\n"
          ]
        }
      ],
      "source": [
        "# Download and install cloudflared\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared\n",
        "\n",
        "print(\"Cloudflare tunnel client installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji-K4diXFPwE"
      },
      "source": [
        "## 6. Start the FastAPI Service\n",
        "\n",
        "Now we'll run the FastAPI application in the background and expose it through the Cloudflare tunnel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25200ab8",
        "outputId": "2b7572ae-4850-4bcc-f79a-4b8cd6cbcc69"
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import signal\n",
        "\n",
        "# Function to kill any process using a specific port\n",
        "def kill_port(port):\n",
        "    \"\"\"Kill any process using the specified port\"\"\"\n",
        "    try:\n",
        "        print(f\"Checking for processes using port {port}...\")\n",
        "        # Find processes using the port\n",
        "        result = subprocess.run(\n",
        "            [\"lsof\", \"-ti\", f\":{port}\"],\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0 and result.stdout.strip():\n",
        "            pids = result.stdout.strip().split('\\n')\n",
        "            for pid in pids:\n",
        "                if pid:\n",
        "                    print(f\"Killing process {pid} using port {port}\")\n",
        "                    try:\n",
        "                        os.kill(int(pid), signal.SIGTERM)\n",
        "                        time.sleep(1)  # Give it a moment to terminate gracefully\n",
        "                        # If still running, force kill\n",
        "                        try:\n",
        "                            os.kill(int(pid), signal.SIGKILL)\n",
        "                        except ProcessLookupError:\n",
        "                            pass  # Process already terminated\n",
        "                    except (ProcessLookupError, ValueError):\n",
        "                        print(f\"Process {pid} not found or invalid PID\")\n",
        "            print(f\"All processes on port {port} have been terminated\")\n",
        "        else:\n",
        "            print(f\"No processes found using port {port}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking port {port}: {e}\")\n",
        "\n",
        "# Function to start FastAPI server in a background process\n",
        "def start_fastapi_background():\n",
        "    print(\"Attempting to start FastAPI server in background using subprocess...\")\n",
        "    try:\n",
        "        # Kill any existing processes on port 8000\n",
        "        kill_port(8000)\n",
        "\n",
        "        # Check if we're already in the whisperX-FastAPI directory\n",
        "        current_dir = os.path.basename(os.getcwd())\n",
        "        if current_dir != \"whisperX-FastAPI\":\n",
        "            os.chdir(\"whisperX-FastAPI\")\n",
        "            print(f\"Changed directory to whisperX-FastAPI\")\n",
        "        else:\n",
        "            print(\"Already in whisperX-FastAPI directory\")\n",
        "\n",
        "        # Define the command to run (using port 8000 instead of 8001)\n",
        "        # Use 'exec' to replace the current shell process with uvicorn,\n",
        "        # and run in the background with '&'\n",
        "        # Ensure the virtual environment is sourced\n",
        "        command = \"uvicorn app.main:app --host 0.0.0.0 --port 8000 --log-config app/uvicorn_log_conf.yaml --log-level info &\"\n",
        "\n",
        "        # Start the subprocess\n",
        "        # We don't need to capture stdout/stderr if we want it to run truly in background\n",
        "        # If we need to debug, we might temporarily remove '&' and check output\n",
        "        process = subprocess.Popen(command, shell=True, preexec_fn=os.setsid)\n",
        "\n",
        "        print(f\"FastAPI background process started with PID: {process.pid}\")\n",
        "        return process\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error starting FastAPI background process: {e}\")\n",
        "        return None\n",
        "\n",
        "# Start the background process\n",
        "fastapi_process = start_fastapi_background()\n",
        "\n",
        "# Give the server a moment to start\n",
        "time.sleep(30)\n",
        "\n",
        "# Now check if the server is reachable\n",
        "global server_url\n",
        "server_url = \"http://0.0.0.0:8000\"\n",
        "print(f\"Attempting to connect to FastAPI server at {server_url}...\")\n",
        "\n",
        "try:\n",
        "    response = requests.get(server_url, timeout=30)\n",
        "    print(f\"Successfully connected to {server_url}. Status code: {response.status_code}\")\n",
        "    if response.status_code in [200, 404, 422]:\n",
        "        print(\"FastAPI server appears to be running.\")\n",
        "    else:\n",
        "        print(\"Received unexpected status code. Server might be running but not as expected.\")\n",
        "\n",
        "except requests.exceptions.ConnectionError:\n",
        "    print(f\"Error: Could not connect to {server_url}. The server might not be running or is not accessible.\")\n",
        "except requests.exceptions.Timeout:\n",
        "    print(f\"Error: Request to {server_url} timed out.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Store the process globally if needed for later shutdown\n",
        "globals()['fastapi_background_process'] = fastapi_process"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to start FastAPI server in background using subprocess...\n",
            "Checking for processes using port 8000...\n",
            "No processes found using port 8000\n",
            "Changed directory to whisperX-FastAPI\n",
            "FastAPI background process started with PID: 15032\n",
            "Attempting to connect to FastAPI server at http://0.0.0.0:8000...\n",
            "Successfully connected to http://0.0.0.0:8000. Status code: 200\n",
            "FastAPI server appears to be running.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import subprocess\n",
        "import time\n",
        "import threading\n",
        "import IPython.display\n",
        "from queue import Queue, Empty\n",
        "\n",
        "def stream_output(process, output_queue):\n",
        "    \"\"\"Read output from process and put it in the queue\"\"\"\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        if not line:\n",
        "            break\n",
        "        output_queue.put(line)\n",
        "    process.stdout.close()\n",
        "\n",
        "# Start cloudflared in a more controlled way\n",
        "print(\"Starting Cloudflare tunnel...\")\n",
        "output_queue = Queue()\n",
        "\n",
        "# Force kill any existing cloudflared processes that might be running\n",
        "try:\n",
        "    subprocess.run(['pkill', '-f', 'cloudflared'], check=False)\n",
        "    time.sleep(1)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Run cloudflared with proper error handling\n",
        "try:\n",
        "    cloudflared_proc = subprocess.Popen(\n",
        "        ['./cloudflared', 'tunnel', '--url', server_url, '--no-autoupdate'],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        bufsize=1\n",
        "    )\n",
        "\n",
        "    # Store the process for later cleanup\n",
        "    globals()['cloudflared_proc'] = cloudflared_proc\n",
        "\n",
        "    # Start thread to read output without blocking\n",
        "    output_thread = threading.Thread(\n",
        "        target=stream_output,\n",
        "        args=(cloudflared_proc, output_queue)\n",
        "    )\n",
        "    output_thread.daemon = True\n",
        "    output_thread.start()\n",
        "\n",
        "    # Wait for the tunnel URL to appear\n",
        "    tunnel_url = None\n",
        "    start_time = time.time()\n",
        "    timeout = 30  # 30 seconds timeout\n",
        "\n",
        "    print(\"Waiting for tunnel URL (this may take a few seconds)...\")\n",
        "\n",
        "    while time.time() - start_time < timeout:\n",
        "        try:\n",
        "            line = output_queue.get(timeout=0.5)\n",
        "            print(line.strip())\n",
        "\n",
        "            match = re.search(r'(https://.*\\.trycloudflare\\.com)', line)\n",
        "            if match:\n",
        "                tunnel_url = match.group(1)\n",
        "                break\n",
        "        except Empty:\n",
        "            pass\n",
        "\n",
        "    if tunnel_url:\n",
        "        print(f\"\\n✅ Public URL for WhisperX-FastAPI:\\n{tunnel_url}\")\n",
        "\n",
        "        # Display a clickable link\n",
        "        display(IPython.display.HTML(f'<a href=\"{tunnel_url}/docs\" target=\"_blank\">Open API Documentation</a>'))\n",
        "\n",
        "        time.sleep(15)\n",
        "        # Check if the tunnel is working\n",
        "        import requests\n",
        "        try:\n",
        "            health_check = requests.get(f\"{tunnel_url}/health\", timeout=15)\n",
        "            if health_check.status_code == 200:\n",
        "                print(\"✅ API is accessible through the tunnel\")\n",
        "            else:\n",
        "                print(f\"⚠️ API responded with status code: {health_check.status_code}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not connect to API through tunnel: {str(e)}\")\n",
        "    else:\n",
        "        print(\"❌ Could not find public Cloudflare URL within timeout period.\")\n",
        "        print(\"You may need to restart this cell.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error starting Cloudflare tunnel: {str(e)}\")\n",
        "    if 'cloudflared_proc' in globals() and globals()['cloudflared_proc']:\n",
        "        globals()['cloudflared_proc'].terminate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "zrzQIdfoJJa1",
        "outputId": "5341c00d-e141-41f0-c21c-863a1c44ddb1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Cloudflare tunnel...\n",
            "Waiting for tunnel URL (this may take a few seconds)...\n",
            "2025-06-23T16:16:30Z INF Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "2025-06-23T16:16:30Z INF Requesting new quick Tunnel on trycloudflare.com...\n",
            "2025-06-23T16:16:34Z INF +--------------------------------------------------------------------------------------------+\n",
            "2025-06-23T16:16:34Z INF |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "2025-06-23T16:16:34Z INF |  https://rna-quiet-screenshots-videos.trycloudflare.com                                    |\n",
            "\n",
            "✅ Public URL for WhisperX-FastAPI:\n",
            "https://rna-quiet-screenshots-videos.trycloudflare.com\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<a href=\"https://rna-quiet-screenshots-videos.trycloudflare.com/docs\" target=\"_blank\">Open API Documentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ API is accessible through the tunnel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VceFvDDVFPwF"
      },
      "source": [
        "## 10. Shutdown Services\n",
        "\n",
        "When you're done, use this cell to properly shut down the services and free up resources."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to shut down services\n",
        "def shutdown_services():\n",
        "    global fastapi_process, cloudflared_proc\n",
        "\n",
        "    print(\"Shutting down services...\")\n",
        "\n",
        "    # Terminate Cloudflare tunnel\n",
        "    if 'cloudflared_proc' in globals() and cloudflared_proc:\n",
        "        print(\"Stopping Cloudflare tunnel...\")\n",
        "        try:\n",
        "            # Send SIGTERM to the process\n",
        "            cloudflared_proc.terminate()\n",
        "\n",
        "            # Wait for up to 5 seconds for graceful termination\n",
        "            for _ in range(5):\n",
        "                if cloudflared_proc.poll() is not None:\n",
        "                    break\n",
        "                time.sleep(1)\n",
        "\n",
        "            # If still running, force kill\n",
        "            if cloudflared_proc.poll() is None:\n",
        "                cloudflared_proc.kill()\n",
        "                cloudflared_proc.wait()\n",
        "\n",
        "            print(\"Cloudflare tunnel stopped.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error stopping Cloudflare tunnel: {e}\")\n",
        "\n",
        "    # Terminate FastAPI server\n",
        "    if 'fastapi_process' in globals() and fastapi_process:\n",
        "        print(\"Stopping FastAPI server...\")\n",
        "        try:\n",
        "            import os\n",
        "            import signal\n",
        "\n",
        "            # Use process group ID to kill all child processes\n",
        "            os.killpg(os.getpgid(fastapi_process.pid), signal.SIGTERM)\n",
        "\n",
        "            # Wait for up to 5 seconds for graceful termination\n",
        "            for _ in range(5):\n",
        "                if fastapi_process.poll() is not None:\n",
        "                    break\n",
        "                time.sleep(1)\n",
        "\n",
        "            # If still running, force kill\n",
        "            if fastapi_process.poll() is None:\n",
        "                os.killpg(os.getpgid(fastapi_process.pid), signal.SIGKILL)\n",
        "\n",
        "            print(\"FastAPI server stopped.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error stopping FastAPI server: {e}\")\n",
        "\n",
        "    print(\"All services have been shut down.\")\n",
        "\n",
        "# For manual shutdown, uncomment and run the following line:\n",
        "shutdown_services()"
      ],
      "metadata": {
        "id": "H6sY7e3Ggw4T",
        "outputId": "5edf0516-92bb-4ed9-eeb5-ca79e5986f55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shutting down services...\n",
            "Stopping Cloudflare tunnel...\n",
            "Cloudflare tunnel stopped.\n",
            "Stopping FastAPI server...\n",
            "Error stopping FastAPI server: [Errno 3] No such process\n",
            "All services have been shut down.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KkSIjl4FPwG"
      },
      "source": [
        "## 11. Cleanup\n",
        "\n",
        "Finally, clean up any temporary files and free up GPU memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0e9m8RoFPwG"
      },
      "outputs": [],
      "source": [
        "# Clean up temporary files\n",
        "!rm -f cloudflared-linux-amd64.deb\n",
        "\n",
        "# Free up GPU memory (if any is still in use)\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"GPU memory cleared.\")\n",
        "\n",
        "print(\"Cleanup completed. You can now close this notebook or run it again if needed.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}