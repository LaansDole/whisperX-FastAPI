{
  "openapi": "3.1.0",
  "info": {
    "title": "whisperX REST service",
    "description": "\n    # whisperX RESTful API\n\n    Welcome to the whisperX RESTful API! This API provides a suite of audio processing services to enhance and analyze your audio content.\n\n    ## Documentation:\n\n    For detailed information on request and response formats, consult the [WhisperX Documentation](https://github.com/m-bain/whisperX).\n\n    ## Services:\n\n    Speech-2-Text provides a suite of audio processing services to enhance and analyze your audio content. The following services are available:\n\n    1. Transcribe: Transcribe an audio/video  file into text.\n    2. Align: Align the transcript to the audio/video file.\n    3. Diarize: Diarize an audio/video file into speakers.\n    4. Combine Transcript and Diarization: Combine the transcript and diarization results.\n\n    ## Supported file extensions:\n    AUDIO_EXTENSIONS = {'.ogg', '.aac', '.m4a', '.amr', '.awb', '.wma', '.mp3', '.wav', '.oga'}\n\n    VIDEO_EXTENSIONS = {'.wmv', '.mkv', '.mov', '.mp4', '.avi'}\n\n    ",
    "version": "0.0.1"
  },
  "paths": {
    "/speech-to-text": {
      "post": {
        "tags": [
          "Speech-2-Text"
        ],
        "summary": "Speech To Text",
        "description": "Process an uploaded audio file for speech-to-text conversion.",
        "operationId": "speech_to_text_speech_to_text_post",
        "parameters": [
          {
            "name": "language",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Language to transcribe",
              "enum": [
                "en",
                "zh",
                "de",
                "es",
                "ru",
                "ko",
                "fr",
                "ja",
                "pt",
                "tr",
                "pl",
                "ca",
                "nl",
                "ar",
                "sv",
                "it",
                "id",
                "hi",
                "fi",
                "vi",
                "he",
                "uk",
                "el",
                "ms",
                "cs",
                "ro",
                "da",
                "hu",
                "ta",
                "no",
                "th",
                "ur",
                "hr",
                "bg",
                "lt",
                "la",
                "mi",
                "ml",
                "cy",
                "sk",
                "te",
                "fa",
                "lv",
                "bn",
                "sr",
                "az",
                "sl",
                "kn",
                "et",
                "mk",
                "br",
                "eu",
                "is",
                "hy",
                "ne",
                "mn",
                "bs",
                "kk",
                "sq",
                "sw",
                "gl",
                "mr",
                "pa",
                "si",
                "km",
                "sn",
                "yo",
                "so",
                "af",
                "oc",
                "ka",
                "be",
                "tg",
                "sd",
                "gu",
                "am",
                "yi",
                "lo",
                "uz",
                "fo",
                "ht",
                "ps",
                "tk",
                "nn",
                "mt",
                "sa",
                "lb",
                "my",
                "bo",
                "tl",
                "mg",
                "as",
                "tt",
                "haw",
                "ln",
                "ha",
                "ba",
                "jw",
                "su",
                "yue"
              ],
              "default": "en",
              "title": "Language"
            },
            "description": "Language to transcribe"
          },
          {
            "name": "task",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/TaskEnum",
              "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
              "default": "transcribe"
            },
            "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')"
          },
          {
            "name": "model",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/WhisperModel",
              "description": "Name of the Whisper model to use",
              "default": "small"
            },
            "description": "Name of the Whisper model to use"
          },
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cpu"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "device_index",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Device index to use for FasterWhisper inference",
              "default": 0,
              "title": "Device Index"
            },
            "description": "Device index to use for FasterWhisper inference"
          },
          {
            "name": "threads",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS",
              "default": 0,
              "title": "Threads"
            },
            "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS"
          },
          {
            "name": "batch_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "The preferred batch size for inference",
              "default": 8,
              "title": "Batch Size"
            },
            "description": "The preferred batch size for inference"
          },
          {
            "name": "chunk_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long.",
              "default": 20,
              "title": "Chunk Size"
            },
            "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long."
          },
          {
            "name": "compute_type",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/ComputeType",
              "description": "Type of computation",
              "default": "int8"
            },
            "description": "Type of computation"
          },
          {
            "name": "use_meralion",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Use MERaLiON model as primary transcription engine",
              "default": true,
              "title": "Use Meralion"
            },
            "description": "Use MERaLiON model as primary transcription engine"
          },
          {
            "name": "meralion_fallback_enabled",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Enable fallback to Whisper models if MERaLiON fails",
              "default": true,
              "title": "Meralion Fallback Enabled"
            },
            "description": "Enable fallback to Whisper models if MERaLiON fails"
          },
          {
            "name": "meralion_max_new_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Maximum number of tokens to generate with MERaLiON",
              "default": 256,
              "title": "Meralion Max New Tokens"
            },
            "description": "Maximum number of tokens to generate with MERaLiON"
          },
          {
            "name": "align_model",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Name of phoneme-level ASR model to do alignment",
              "title": "Align Model"
            },
            "description": "Name of phoneme-level ASR model to do alignment"
          },
          {
            "name": "interpolate_method",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/InterpolateMethod",
              "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring.",
              "default": "nearest"
            },
            "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring."
          },
          {
            "name": "return_char_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return character-level alignments in the output json file",
              "default": false,
              "title": "Return Char Alignments"
            },
            "description": "Return character-level alignments in the output json file"
          },
          {
            "name": "return_word_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return word-level alignments in the output json file",
              "default": false,
              "title": "Return Word Alignments"
            },
            "description": "Return word-level alignments in the output json file"
          },
          {
            "name": "min_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Minimum number of speakers to in audio file",
              "title": "Min Speakers"
            },
            "description": "Minimum number of speakers to in audio file"
          },
          {
            "name": "max_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Maximum number of speakers to in audio file",
              "title": "Max Speakers"
            },
            "description": "Maximum number of speakers to in audio file"
          },
          {
            "name": "beam_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Beam Size"
            },
            "description": "Number of beams in beam search, only applicable when temperature is zero"
          },
          {
            "name": "best_of",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams to keep in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Best Of"
            },
            "description": "Number of beams to keep in beam search, only applicable when temperature is zero"
          },
          {
            "name": "patience",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional patience value to use in beam decoding",
              "default": 1.0,
              "title": "Patience"
            },
            "description": "Optional patience value to use in beam decoding"
          },
          {
            "name": "length_penalty",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional token length penalty coefficient",
              "default": 1.0,
              "title": "Length Penalty"
            },
            "description": "Optional token length penalty coefficient"
          },
          {
            "name": "temperatures",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Temperature to use for sampling",
              "default": 0.0,
              "title": "Temperatures"
            },
            "description": "Temperature to use for sampling"
          },
          {
            "name": "compression_ratio_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed",
              "default": 2.4,
              "title": "Compression Ratio Threshold"
            },
            "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed"
          },
          {
            "name": "log_prob_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the average log probability is lower than this value, treat the decoding as failed",
              "default": -1.0,
              "title": "Log Prob Threshold"
            },
            "description": "If the average log probability is lower than this value, treat the decoding as failed"
          },
          {
            "name": "no_speech_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
              "default": 0.6,
              "title": "No Speech Threshold"
            },
            "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence"
          },
          {
            "name": "initial_prompt",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Optional text to provide as a prompt for the first window.",
              "title": "Initial Prompt"
            },
            "description": "Optional text to provide as a prompt for the first window."
          },
          {
            "name": "suppress_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "array",
              "items": {
                "type": "integer"
              },
              "description": "Comma-separated list of token ids to suppress during sampling",
              "default": [
                -1
              ],
              "title": "Suppress Tokens"
            },
            "description": "Comma-separated list of token ids to suppress during sampling"
          },
          {
            "name": "suppress_numerals",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "boolean"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Whether to suppress numeric symbols and currency symbols during sampling",
              "default": false,
              "title": "Suppress Numerals"
            },
            "description": "Whether to suppress numeric symbols and currency symbols during sampling"
          },
          {
            "name": "hotwords",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Hotwords related prompt applied before each transcription window",
              "title": "Hotwords"
            },
            "description": "Hotwords related prompt applied before each transcription window"
          },
          {
            "name": "vad_onset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected",
              "default": 0.5,
              "title": "Vad Onset"
            },
            "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected"
          },
          {
            "name": "vad_offset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.",
              "default": 0.363,
              "title": "Vad Offset"
            },
            "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected."
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_speech_to_text_speech_to_text_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/speech-to-text-url": {
      "post": {
        "tags": [
          "Speech-2-Text"
        ],
        "summary": "Speech To Text Url",
        "description": "Process an audio file from a URL for speech-to-text conversion.",
        "operationId": "speech_to_text_url_speech_to_text_url_post",
        "parameters": [
          {
            "name": "language",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Language to transcribe",
              "enum": [
                "en",
                "zh",
                "de",
                "es",
                "ru",
                "ko",
                "fr",
                "ja",
                "pt",
                "tr",
                "pl",
                "ca",
                "nl",
                "ar",
                "sv",
                "it",
                "id",
                "hi",
                "fi",
                "vi",
                "he",
                "uk",
                "el",
                "ms",
                "cs",
                "ro",
                "da",
                "hu",
                "ta",
                "no",
                "th",
                "ur",
                "hr",
                "bg",
                "lt",
                "la",
                "mi",
                "ml",
                "cy",
                "sk",
                "te",
                "fa",
                "lv",
                "bn",
                "sr",
                "az",
                "sl",
                "kn",
                "et",
                "mk",
                "br",
                "eu",
                "is",
                "hy",
                "ne",
                "mn",
                "bs",
                "kk",
                "sq",
                "sw",
                "gl",
                "mr",
                "pa",
                "si",
                "km",
                "sn",
                "yo",
                "so",
                "af",
                "oc",
                "ka",
                "be",
                "tg",
                "sd",
                "gu",
                "am",
                "yi",
                "lo",
                "uz",
                "fo",
                "ht",
                "ps",
                "tk",
                "nn",
                "mt",
                "sa",
                "lb",
                "my",
                "bo",
                "tl",
                "mg",
                "as",
                "tt",
                "haw",
                "ln",
                "ha",
                "ba",
                "jw",
                "su",
                "yue"
              ],
              "default": "en",
              "title": "Language"
            },
            "description": "Language to transcribe"
          },
          {
            "name": "task",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/TaskEnum",
              "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
              "default": "transcribe"
            },
            "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')"
          },
          {
            "name": "model",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/WhisperModel",
              "description": "Name of the Whisper model to use",
              "default": "small"
            },
            "description": "Name of the Whisper model to use"
          },
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cpu"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "device_index",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Device index to use for FasterWhisper inference",
              "default": 0,
              "title": "Device Index"
            },
            "description": "Device index to use for FasterWhisper inference"
          },
          {
            "name": "threads",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS",
              "default": 0,
              "title": "Threads"
            },
            "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS"
          },
          {
            "name": "batch_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "The preferred batch size for inference",
              "default": 8,
              "title": "Batch Size"
            },
            "description": "The preferred batch size for inference"
          },
          {
            "name": "chunk_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long.",
              "default": 20,
              "title": "Chunk Size"
            },
            "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long."
          },
          {
            "name": "compute_type",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/ComputeType",
              "description": "Type of computation",
              "default": "int8"
            },
            "description": "Type of computation"
          },
          {
            "name": "use_meralion",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Use MERaLiON model as primary transcription engine",
              "default": true,
              "title": "Use Meralion"
            },
            "description": "Use MERaLiON model as primary transcription engine"
          },
          {
            "name": "meralion_fallback_enabled",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Enable fallback to Whisper models if MERaLiON fails",
              "default": true,
              "title": "Meralion Fallback Enabled"
            },
            "description": "Enable fallback to Whisper models if MERaLiON fails"
          },
          {
            "name": "meralion_max_new_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Maximum number of tokens to generate with MERaLiON",
              "default": 256,
              "title": "Meralion Max New Tokens"
            },
            "description": "Maximum number of tokens to generate with MERaLiON"
          },
          {
            "name": "align_model",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Name of phoneme-level ASR model to do alignment",
              "title": "Align Model"
            },
            "description": "Name of phoneme-level ASR model to do alignment"
          },
          {
            "name": "interpolate_method",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/InterpolateMethod",
              "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring.",
              "default": "nearest"
            },
            "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring."
          },
          {
            "name": "return_char_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return character-level alignments in the output json file",
              "default": false,
              "title": "Return Char Alignments"
            },
            "description": "Return character-level alignments in the output json file"
          },
          {
            "name": "return_word_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return word-level alignments in the output json file",
              "default": false,
              "title": "Return Word Alignments"
            },
            "description": "Return word-level alignments in the output json file"
          },
          {
            "name": "min_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Minimum number of speakers to in audio file",
              "title": "Min Speakers"
            },
            "description": "Minimum number of speakers to in audio file"
          },
          {
            "name": "max_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Maximum number of speakers to in audio file",
              "title": "Max Speakers"
            },
            "description": "Maximum number of speakers to in audio file"
          },
          {
            "name": "beam_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Beam Size"
            },
            "description": "Number of beams in beam search, only applicable when temperature is zero"
          },
          {
            "name": "best_of",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams to keep in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Best Of"
            },
            "description": "Number of beams to keep in beam search, only applicable when temperature is zero"
          },
          {
            "name": "patience",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional patience value to use in beam decoding",
              "default": 1.0,
              "title": "Patience"
            },
            "description": "Optional patience value to use in beam decoding"
          },
          {
            "name": "length_penalty",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional token length penalty coefficient",
              "default": 1.0,
              "title": "Length Penalty"
            },
            "description": "Optional token length penalty coefficient"
          },
          {
            "name": "temperatures",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Temperature to use for sampling",
              "default": 0.0,
              "title": "Temperatures"
            },
            "description": "Temperature to use for sampling"
          },
          {
            "name": "compression_ratio_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed",
              "default": 2.4,
              "title": "Compression Ratio Threshold"
            },
            "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed"
          },
          {
            "name": "log_prob_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the average log probability is lower than this value, treat the decoding as failed",
              "default": -1.0,
              "title": "Log Prob Threshold"
            },
            "description": "If the average log probability is lower than this value, treat the decoding as failed"
          },
          {
            "name": "no_speech_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
              "default": 0.6,
              "title": "No Speech Threshold"
            },
            "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence"
          },
          {
            "name": "initial_prompt",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Optional text to provide as a prompt for the first window.",
              "title": "Initial Prompt"
            },
            "description": "Optional text to provide as a prompt for the first window."
          },
          {
            "name": "suppress_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "array",
              "items": {
                "type": "integer"
              },
              "description": "Comma-separated list of token ids to suppress during sampling",
              "default": [
                -1
              ],
              "title": "Suppress Tokens"
            },
            "description": "Comma-separated list of token ids to suppress during sampling"
          },
          {
            "name": "suppress_numerals",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "boolean"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Whether to suppress numeric symbols and currency symbols during sampling",
              "default": false,
              "title": "Suppress Numerals"
            },
            "description": "Whether to suppress numeric symbols and currency symbols during sampling"
          },
          {
            "name": "hotwords",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Hotwords related prompt applied before each transcription window",
              "title": "Hotwords"
            },
            "description": "Hotwords related prompt applied before each transcription window"
          },
          {
            "name": "vad_onset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected",
              "default": 0.5,
              "title": "Vad Onset"
            },
            "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected"
          },
          {
            "name": "vad_offset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.",
              "default": 0.363,
              "title": "Vad Offset"
            },
            "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected."
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/x-www-form-urlencoded": {
              "schema": {
                "$ref": "#/components/schemas/Body_speech_to_text_url_speech_to_text_url_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/speech-to-text-meralion": {
      "post": {
        "tags": [
          "Speech-2-Text"
        ],
        "summary": "Speech To Text Meralion",
        "description": "Process audio using MERaLiON-AudioLLM-Whisper-SEA-LION model with fallback to Whisper models.\n\nThis endpoint prioritizes the MERaLiON model for transcription and translation tasks,\nwith automatic fallback to traditional Whisper models when needed. Optimized for\nSingapore English ('sg') by default.",
        "operationId": "speech_to_text_meralion_speech_to_text_meralion_post",
        "requestBody": {
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_speech_to_text_meralion_speech_to_text_meralion_post"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/transcribe": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "1. Transcribe",
        "description": "Transcribe an uploaded audio file.",
        "operationId": "1__Transcribe_service_transcribe_post",
        "parameters": [
          {
            "name": "language",
            "in": "query",
            "required": false,
            "schema": {
              "type": "string",
              "description": "Language to transcribe",
              "enum": [
                "en",
                "zh",
                "de",
                "es",
                "ru",
                "ko",
                "fr",
                "ja",
                "pt",
                "tr",
                "pl",
                "ca",
                "nl",
                "ar",
                "sv",
                "it",
                "id",
                "hi",
                "fi",
                "vi",
                "he",
                "uk",
                "el",
                "ms",
                "cs",
                "ro",
                "da",
                "hu",
                "ta",
                "no",
                "th",
                "ur",
                "hr",
                "bg",
                "lt",
                "la",
                "mi",
                "ml",
                "cy",
                "sk",
                "te",
                "fa",
                "lv",
                "bn",
                "sr",
                "az",
                "sl",
                "kn",
                "et",
                "mk",
                "br",
                "eu",
                "is",
                "hy",
                "ne",
                "mn",
                "bs",
                "kk",
                "sq",
                "sw",
                "gl",
                "mr",
                "pa",
                "si",
                "km",
                "sn",
                "yo",
                "so",
                "af",
                "oc",
                "ka",
                "be",
                "tg",
                "sd",
                "gu",
                "am",
                "yi",
                "lo",
                "uz",
                "fo",
                "ht",
                "ps",
                "tk",
                "nn",
                "mt",
                "sa",
                "lb",
                "my",
                "bo",
                "tl",
                "mg",
                "as",
                "tt",
                "haw",
                "ln",
                "ha",
                "ba",
                "jw",
                "su",
                "yue"
              ],
              "default": "en",
              "title": "Language"
            },
            "description": "Language to transcribe"
          },
          {
            "name": "task",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/TaskEnum",
              "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')",
              "default": "transcribe"
            },
            "description": "Whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')"
          },
          {
            "name": "model",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/WhisperModel",
              "description": "Name of the Whisper model to use",
              "default": "small"
            },
            "description": "Name of the Whisper model to use"
          },
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cpu"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "device_index",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Device index to use for FasterWhisper inference",
              "default": 0,
              "title": "Device Index"
            },
            "description": "Device index to use for FasterWhisper inference"
          },
          {
            "name": "threads",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS",
              "default": 0,
              "title": "Threads"
            },
            "description": "Number of threads used by torch for CPU inference; supersedes MKL_NUM_THREADS/OMP_NUM_THREADS"
          },
          {
            "name": "batch_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "The preferred batch size for inference",
              "default": 8,
              "title": "Batch Size"
            },
            "description": "The preferred batch size for inference"
          },
          {
            "name": "chunk_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long.",
              "default": 20,
              "title": "Chunk Size"
            },
            "description": "Chunk size for merging VAD segments. Default is 20, reduce this if the chunk is too long."
          },
          {
            "name": "compute_type",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/ComputeType",
              "description": "Type of computation",
              "default": "int8"
            },
            "description": "Type of computation"
          },
          {
            "name": "use_meralion",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Use MERaLiON model as primary transcription engine",
              "default": true,
              "title": "Use Meralion"
            },
            "description": "Use MERaLiON model as primary transcription engine"
          },
          {
            "name": "meralion_fallback_enabled",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Enable fallback to Whisper models if MERaLiON fails",
              "default": true,
              "title": "Meralion Fallback Enabled"
            },
            "description": "Enable fallback to Whisper models if MERaLiON fails"
          },
          {
            "name": "meralion_max_new_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Maximum number of tokens to generate with MERaLiON",
              "default": 256,
              "title": "Meralion Max New Tokens"
            },
            "description": "Maximum number of tokens to generate with MERaLiON"
          },
          {
            "name": "beam_size",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Beam Size"
            },
            "description": "Number of beams in beam search, only applicable when temperature is zero"
          },
          {
            "name": "best_of",
            "in": "query",
            "required": false,
            "schema": {
              "type": "integer",
              "description": "Number of beams to keep in beam search, only applicable when temperature is zero",
              "default": 5,
              "title": "Best Of"
            },
            "description": "Number of beams to keep in beam search, only applicable when temperature is zero"
          },
          {
            "name": "patience",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional patience value to use in beam decoding",
              "default": 1.0,
              "title": "Patience"
            },
            "description": "Optional patience value to use in beam decoding"
          },
          {
            "name": "length_penalty",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Optional token length penalty coefficient",
              "default": 1.0,
              "title": "Length Penalty"
            },
            "description": "Optional token length penalty coefficient"
          },
          {
            "name": "temperatures",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Temperature to use for sampling",
              "default": 0.0,
              "title": "Temperatures"
            },
            "description": "Temperature to use for sampling"
          },
          {
            "name": "compression_ratio_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed",
              "default": 2.4,
              "title": "Compression Ratio Threshold"
            },
            "description": "If the gzip compression ratio is higher than this value, treat the decoding as failed"
          },
          {
            "name": "log_prob_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the average log probability is lower than this value, treat the decoding as failed",
              "default": -1.0,
              "title": "Log Prob Threshold"
            },
            "description": "If the average log probability is lower than this value, treat the decoding as failed"
          },
          {
            "name": "no_speech_threshold",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence",
              "default": 0.6,
              "title": "No Speech Threshold"
            },
            "description": "If the probability of the token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence"
          },
          {
            "name": "initial_prompt",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Optional text to provide as a prompt for the first window.",
              "title": "Initial Prompt"
            },
            "description": "Optional text to provide as a prompt for the first window."
          },
          {
            "name": "suppress_tokens",
            "in": "query",
            "required": false,
            "schema": {
              "type": "array",
              "items": {
                "type": "integer"
              },
              "description": "Comma-separated list of token ids to suppress during sampling",
              "default": [
                -1
              ],
              "title": "Suppress Tokens"
            },
            "description": "Comma-separated list of token ids to suppress during sampling"
          },
          {
            "name": "suppress_numerals",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "boolean"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Whether to suppress numeric symbols and currency symbols during sampling",
              "default": false,
              "title": "Suppress Numerals"
            },
            "description": "Whether to suppress numeric symbols and currency symbols during sampling"
          },
          {
            "name": "hotwords",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Hotwords related prompt applied before each transcription window",
              "title": "Hotwords"
            },
            "description": "Hotwords related prompt applied before each transcription window"
          },
          {
            "name": "vad_onset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected",
              "default": 0.5,
              "title": "Vad Onset"
            },
            "description": "Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected"
          },
          {
            "name": "vad_offset",
            "in": "query",
            "required": false,
            "schema": {
              "type": "number",
              "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.",
              "default": 0.363,
              "title": "Vad Offset"
            },
            "description": "Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected."
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_1__Transcribe_service_transcribe_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/align": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "2. Align Transcript",
        "description": "Align a transcript with an audio file.",
        "operationId": "2__Align_Transcript_service_align_post",
        "parameters": [
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cpu"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "align_model",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Name of phoneme-level ASR model to do alignment",
              "title": "Align Model"
            },
            "description": "Name of phoneme-level ASR model to do alignment"
          },
          {
            "name": "interpolate_method",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/InterpolateMethod",
              "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring.",
              "default": "nearest"
            },
            "description": "For word .srt, method to assign timestamps to non-aligned words, or merge them into neighboring."
          },
          {
            "name": "return_char_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return character-level alignments in the output json file",
              "default": false,
              "title": "Return Char Alignments"
            },
            "description": "Return character-level alignments in the output json file"
          },
          {
            "name": "return_word_alignments",
            "in": "query",
            "required": false,
            "schema": {
              "type": "boolean",
              "description": "Return word-level alignments in the output json file",
              "default": false,
              "title": "Return Word Alignments"
            },
            "description": "Return word-level alignments in the output json file"
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_2__Align_Transcript_service_align_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/diarize": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "3. Diarize",
        "description": "Perform diarization on an uploaded audio file.",
        "operationId": "3__Diarize_service_diarize_post",
        "parameters": [
          {
            "name": "device",
            "in": "query",
            "required": false,
            "schema": {
              "$ref": "#/components/schemas/Device",
              "description": "Device to use for PyTorch inference",
              "default": "cpu"
            },
            "description": "Device to use for PyTorch inference"
          },
          {
            "name": "min_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Minimum number of speakers to in audio file",
              "title": "Min Speakers"
            },
            "description": "Minimum number of speakers to in audio file"
          },
          {
            "name": "max_speakers",
            "in": "query",
            "required": false,
            "schema": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "description": "Maximum number of speakers to in audio file",
              "title": "Max Speakers"
            },
            "description": "Maximum number of speakers to in audio file"
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_3__Diarize_service_diarize_post"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/service/combine": {
      "post": {
        "tags": [
          "Speech-2-Text services"
        ],
        "summary": "4. Combine Transcript And Diarization Result",
        "description": "Combine a transcript with diarization results.",
        "operationId": "4__Combine_Transcript_and_Diarization_result_service_combine_post",
        "requestBody": {
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/Body_4__Combine_Transcript_and_Diarization_result_service_combine_post"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Response"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/temporal/workflow": {
      "post": {
        "tags": [
          "Temporal"
        ],
        "summary": "Start Workflow",
        "operationId": "start_workflow_temporal_workflow_post",
        "parameters": [
          {
            "name": "audio_path",
            "in": "query",
            "required": true,
            "schema": {
              "type": "string",
              "title": "Audio Path"
            }
          }
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "type": "object",
                "additionalProperties": true,
                "title": "Params"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/temporal/workflow/{workflow_id}": {
      "get": {
        "tags": [
          "Temporal"
        ],
        "summary": "Get Workflow Status",
        "operationId": "get_workflow_status_temporal_workflow__workflow_id__get",
        "parameters": [
          {
            "name": "workflow_id",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string",
              "title": "Workflow Id"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/temporal/workflow/{workflow_id}/result": {
      "get": {
        "tags": [
          "Temporal"
        ],
        "summary": "Get Workflow Result",
        "operationId": "get_workflow_result_temporal_workflow__workflow_id__result_get",
        "parameters": [
          {
            "name": "workflow_id",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string",
              "title": "Workflow Id"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HTTPValidationError"
                }
              }
            }
          }
        }
      }
    },
    "/health": {
      "get": {
        "tags": [
          "Health"
        ],
        "summary": "Simple health check",
        "description": "Verify the service is up and running.\n\nReturns a simple status response to confirm the API service is operational.",
        "operationId": "health_check_health_get",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          }
        }
      }
    },
    "/health/live": {
      "get": {
        "tags": [
          "Health"
        ],
        "summary": "Liveness check",
        "description": "Check if the application is running.\n\nUsed by orchestration systems like Kubernetes to detect if the app is alive.\nReturns timestamp along with status information.",
        "operationId": "liveness_check_health_live_get",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          }
        }
      }
    },
    "/health/ready": {
      "get": {
        "tags": [
          "Health"
        ],
        "summary": "Readiness check",
        "description": "Check if the application is ready to accept requests.\nVerifies dependencies like the Temporal server are connected and ready.\nReturns HTTP 200 if all systems are operational, HTTP 503 if any dependency\nhas failed.",
        "operationId": "readiness_check_health_ready_get",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {}
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "Body_1__Transcribe_service_transcribe_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File",
            "description": "Audio/video file to transcribe"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_1__Transcribe_service_transcribe_post"
      },
      "Body_2__Align_Transcript_service_align_post": {
        "properties": {
          "transcript": {
            "type": "string",
            "format": "binary",
            "title": "Transcript",
            "description": "Whisper style transcript json file"
          },
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File",
            "description": "Audio/video file which has been transcribed"
          }
        },
        "type": "object",
        "required": [
          "transcript",
          "file"
        ],
        "title": "Body_2__Align_Transcript_service_align_post"
      },
      "Body_3__Diarize_service_diarize_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_3__Diarize_service_diarize_post"
      },
      "Body_4__Combine_Transcript_and_Diarization_result_service_combine_post": {
        "properties": {
          "aligned_transcript": {
            "type": "string",
            "format": "binary",
            "title": "Aligned Transcript"
          },
          "diarization_result": {
            "type": "string",
            "format": "binary",
            "title": "Diarization Result"
          }
        },
        "type": "object",
        "required": [
          "aligned_transcript",
          "diarization_result"
        ],
        "title": "Body_4__Combine_Transcript_and_Diarization_result_service_combine_post"
      },
      "Body_speech_to_text_meralion_speech_to_text_meralion_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File"
          },
          "language": {
            "type": "string",
            "title": "Language",
            "description": "Target language code (e.g., 'sg', 'en', 'zh', 'vi')",
            "default": "sg"
          },
          "task": {
            "type": "string",
            "title": "Task",
            "description": "Task: 'transcribe' or 'translate'",
            "default": "transcribe"
          },
          "device": {
            "type": "string",
            "title": "Device",
            "description": "Device: 'auto', 'cpu', or 'cuda'",
            "default": "auto"
          },
          "use_meralion": {
            "type": "boolean",
            "title": "Use Meralion",
            "description": "Use MERaLiON model as primary transcription engine",
            "default": true
          },
          "meralion_fallback_enabled": {
            "type": "boolean",
            "title": "Meralion Fallback Enabled",
            "description": "Enable fallback to Whisper models if MERaLiON fails",
            "default": true
          },
          "meralion_max_new_tokens": {
            "type": "integer",
            "title": "Meralion Max New Tokens",
            "description": "Maximum tokens for MERaLiON generation",
            "default": 256
          },
          "return_word_alignments": {
            "type": "boolean",
            "title": "Return Word Alignments",
            "description": "Return word-level timestamps",
            "default": false
          },
          "return_char_alignments": {
            "type": "boolean",
            "title": "Return Char Alignments",
            "description": "Return character-level timestamps",
            "default": false
          },
          "min_speakers": {
            "anyOf": [
              {
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "title": "Min Speakers",
            "description": "Minimum number of speakers (optional)"
          },
          "max_speakers": {
            "anyOf": [
              {
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "title": "Max Speakers",
            "description": "Maximum number of speakers (optional)"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_speech_to_text_meralion_speech_to_text_meralion_post"
      },
      "Body_speech_to_text_speech_to_text_post": {
        "properties": {
          "file": {
            "type": "string",
            "format": "binary",
            "title": "File"
          }
        },
        "type": "object",
        "required": [
          "file"
        ],
        "title": "Body_speech_to_text_speech_to_text_post"
      },
      "Body_speech_to_text_url_speech_to_text_url_post": {
        "properties": {
          "url": {
            "type": "string",
            "title": "Url"
          }
        },
        "type": "object",
        "required": [
          "url"
        ],
        "title": "Body_speech_to_text_url_speech_to_text_url_post"
      },
      "ComputeType": {
        "type": "string",
        "enum": [
          "float16",
          "float32",
          "int8"
        ],
        "title": "ComputeType",
        "description": "Enum for compute types."
      },
      "Device": {
        "type": "string",
        "enum": [
          "cuda",
          "cpu"
        ],
        "title": "Device",
        "description": "Enum for device types."
      },
      "HTTPValidationError": {
        "properties": {
          "detail": {
            "items": {
              "$ref": "#/components/schemas/ValidationError"
            },
            "type": "array",
            "title": "Detail"
          }
        },
        "type": "object",
        "title": "HTTPValidationError"
      },
      "InterpolateMethod": {
        "type": "string",
        "enum": [
          "nearest",
          "linear",
          "ignore"
        ],
        "title": "InterpolateMethod",
        "description": "Enum for interpolation methods."
      },
      "Response": {
        "properties": {
          "identifier": {
            "type": "string",
            "title": "Identifier"
          },
          "message": {
            "type": "string",
            "title": "Message"
          }
        },
        "type": "object",
        "required": [
          "identifier",
          "message"
        ],
        "title": "Response",
        "description": "Response model for API responses."
      },
      "TaskEnum": {
        "type": "string",
        "enum": [
          "transcribe",
          "translate"
        ],
        "title": "TaskEnum",
        "description": "Enum for task types."
      },
      "ValidationError": {
        "properties": {
          "loc": {
            "items": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "integer"
                }
              ]
            },
            "type": "array",
            "title": "Location"
          },
          "msg": {
            "type": "string",
            "title": "Message"
          },
          "type": {
            "type": "string",
            "title": "Error Type"
          }
        },
        "type": "object",
        "required": [
          "loc",
          "msg",
          "type"
        ],
        "title": "ValidationError"
      },
      "WhisperModel": {
        "type": "string",
        "enum": [
          "tiny",
          "tiny.en",
          "base",
          "base.en",
          "small",
          "small.en",
          "medium",
          "medium.en",
          "large",
          "large-v1",
          "large-v2",
          "large-v3",
          "large-v3-turbo",
          "distil-large-v2",
          "distil-medium.en",
          "distil-small.en",
          "distil-large-v3",
          "nyrahealth/faster_CrisperWhisper",
          "MERaLiON/MERaLiON-AudioLLM-Whisper-SEA-LION"
        ],
        "title": "WhisperModel",
        "description": "Enum for Whisper model types."
      }
    }
  },
  "tags": [
    {
      "name": "Speech-2-Text",
      "description": "Operations related to transcript"
    },
    {
      "name": "Speech-2-Text services",
      "description": "Individual services for transcript"
    },
    {
      "name": "Tasks Management",
      "description": "Manage tasks."
    },
    {
      "name": "Health",
      "description": "Health check endpoints to monitor application status"
    }
  ]
}