version: '3.8'

services:
  temporal:
    image: temporalio/auto-setup:latest
    ports:
      - "7233:7233"
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=postgres
      - DBNAME=temporal
      - VISIBILITY_DBNAME=temporal_visibility
    depends_on:
      - postgres
    networks:
      - whisperx-network
    healthcheck:
      test: ["CMD", "tctl", "--address", "temporal:7233", "cluster", "health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

  postgres:
    image: postgres:13
    environment:
      - POSTGRES_PASSWORD=temporal
      - POSTGRES_USER=temporal
      - POSTGRES_DB=temporal
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - whisperx-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U temporal"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Temporal Web UI
  temporal-ui:
    image: temporalio/ui:latest
    container_name: temporal-ui
    ports:
      - "8233:8080"
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    depends_on:
      temporal:
        condition: service_healthy
    networks:
      - whisperx-network
    restart: unless-stopped

  # WhisperX FastAPI Application
  whisperx-api:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - INSTALL_GPU=false
    ports:
      - "8000:8000"
    environment:
      - HF_TOKEN=${HF_TOKEN:-}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - DIARIZATION_MODEL_PATH=${DIARIZATION_MODEL_PATH:-}
      - TEMPORAL_SERVER_URL=temporal:7233
      - HIPAA_ENCRYPTION_KEY=${HIPAA_ENCRYPTION_KEY:-default}
      # LM Studio configuration for medical processing (host.docker.internal for Docker-to-host connectivity)
      - LM_STUDIO_BASE_URL=${LM_STUDIO_BASE_URL:-http://host.docker.internal:1234/v1}
      - LM_STUDIO_MODEL=${LM_STUDIO_MODEL:-}
      - LM_STUDIO_MAX_TOKENS=${LM_STUDIO_MAX_TOKENS:-8192}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-bge-reranker-v2-m3}
      - EMBEDDING_DIMENSION=${EMBEDDING_DIMENSION:-1024}
    volumes:
      # Config file (runtime defaults)
      - ./config.yaml:/app/config.yaml:ro
      # Model cache
      - whisperx-huggingface-cache:/root/.cache/huggingface
      - whisperx-torch-cache:/root/.cache/torch
      # Shared file uploads (Docker volume, not host directory)
      - whisperx-uploads:/tmp/uploads
      # Data persistence
      - ./vector_storage:/app/vector_storage
      - ./data:/app/data
      - ./audit_logs:/app/audit_logs
    depends_on:
      temporal:
        condition: service_healthy
    networks:
      - whisperx-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Temporal Worker
  whisperx-worker:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - INSTALL_GPU=false
    stop_grace_period: 30s
    environment:
      - HF_TOKEN=${HF_TOKEN:-}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - DIARIZATION_MODEL_PATH=${DIARIZATION_MODEL_PATH:-}
      - TEMPORAL_SERVER_URL=temporal:7233
      - HIPAA_ENCRYPTION_KEY=${HIPAA_ENCRYPTION_KEY:-default}
      # LM Studio configuration for medical processing (host.docker.internal for Docker-to-host connectivity)
      - LM_STUDIO_BASE_URL=${LM_STUDIO_BASE_URL:-http://host.docker.internal:1234/v1}
      - LM_STUDIO_MODEL=${LM_STUDIO_MODEL:-}
      - LM_STUDIO_MAX_TOKENS=${LM_STUDIO_MAX_TOKENS:-8192}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-bge-reranker-v2-m3}
      - EMBEDDING_DIMENSION=${EMBEDDING_DIMENSION:-1024}
    volumes:
      - ./config.yaml:/app/config.yaml:ro
      - whisperx-huggingface-cache:/root/.cache/huggingface
      - whisperx-torch-cache:/root/.cache/torch
      - whisperx-uploads:/tmp/uploads
      - ./vector_storage:/app/vector_storage
      - ./data:/app/data
      - ./audit_logs:/app/audit_logs
    command: ["uv", "run", "python", "-m", "app.temporal.worker"]
    depends_on:
      temporal:
        condition: service_healthy
    networks:
      - whisperx-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      replicas: 1
  
  streamlit-ui:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    ports:
      - "8501:8501"
    environment:
      - WHISPERX_API_URL=http://whisperx-api:8000
    volumes:
      - ./streamlit_app:/app/streamlit_app
    depends_on:
      whisperx-api:
        condition: service_healthy
    networks:
      - whisperx-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

networks:
  whisperx-network:
    driver: bridge

volumes:
  postgres-data:
  whisperx-huggingface-cache:
  whisperx-torch-cache:
  whisperx-uploads:
